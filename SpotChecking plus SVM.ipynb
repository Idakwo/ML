{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', \n",
    "                'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                'income']\n",
    "\n",
    "dataset = pd.read_csv(url, names = column_names, skipinitialspace=True)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(dataset['income'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the number of missing values in each Series\n",
    "dataset.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check the data type of each column\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Lots of objects, Need to convert\n",
    "#First, check the categories of the series that are objects\n",
    "\n",
    "for col in dataset.columns:\n",
    "    if dataset[col].dtypes == 'object':\n",
    "        num_of_categories = len(dataset[col].unique())\n",
    "        print(\"{col} has {num_of_categories} categories\".format(col=col, num_of_categories=num_of_categories))\n",
    "\n",
    "#Depending on your dataset, you can add a line or two more of code to convert all categories with frequencies less\n",
    "#than, say 35% of the max frequency for that column to 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Break up data set into X and y\n",
    "X = dataset.drop('income', 1)\n",
    "y = dataset['income']\n",
    "\n",
    "#Convert income values to binary\n",
    "#Option 1: Use 'map' method or the 'get_dummies' method\n",
    "#Or a one-liner: y = [0 if x == '<=50K' else 1 for x in y]\n",
    "\n",
    "y = y.map({'<=50K':0, '>50K':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X['education'].value_counts().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now, to work on X\n",
    "#We've seen the number of categories in each (feature)series\n",
    "#Let's check the distribution within the series (using education and native_country as example)\n",
    "\n",
    "print(X['native-country'].value_counts().sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#This will loop through the columns and set categories with freqiencies below a threshold to 'Other'\n",
    "#But this is not what I want...I want only native_country changed\n",
    "threshold = 50  # Remove items less than or equal to threshold\n",
    "for col in X.columns:\n",
    "    freq = X[col].value_counts()\n",
    "    vals_to_remove = freq[freq <= threshold].index.values\n",
    "    X[col].loc[X[col].isin(vals_to_remove)] = 'Other'\n",
    "    \n",
    "\n",
    "#TODO: Try to set threshold to x% of max frequency instead of a rigid number. Line below is not working\n",
    "#threshold = 0.35*(freq.iloc[1].max)\n",
    "\n",
    "for col in X.columns:\n",
    "    freq = X[col].value_counts()\n",
    "    threshold = 100\n",
    "    to_change = freq[freq <= threshold].index\n",
    "    X[col].replace(to_change, np.nan, inplace=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For now, besides United-States, set all other categories in native-countries to \"Other\"\n",
    "X['native-country'] = ['United-States ' if x == 'United-States' else 'Other' for x in X['native-country']]\n",
    "\n",
    "print(X['native-country'].value_counts().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To convert all features with categories into numeric features, create a function using get_dummies\n",
    "\n",
    "# A list of categorical features\n",
    "cat_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                'native-country']\n",
    "\n",
    "# Convert cat_features to numeric\n",
    "def cat_to_num(dataset, cat_faetures):\n",
    "    for f in cat_features:\n",
    "        new_feats = pd.get_dummies(dataset[f], prefix=f, dummy_na=False)\n",
    "        dataset = dataset.drop(f, 1)\n",
    "        dataset = pd.concat([dataset, new_feats], axis=1)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "X = cat_to_num(X, cat_features)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot histograms to show distribution of features against outcomes\n",
    "def plot_histogram(x,y):\n",
    "    plt.hist(list(x[y==0]), alpha=0.5, label='Outcome=0')\n",
    "    plt.hist(list(x[y==1]), alpha=0.5, label='Outcome=1')\n",
    "    plt.title(\"Histogram of '{var_name}' by Outcome Category\".format(var_name=x.name))\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "plot_histogram(X['age'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Spot Check a couple of Algorithms\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "# prepare configuration for cross validation test harness\n",
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 1\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('GBM', GradientBoostingClassifier()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "    cv_results = cross_validation.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    scores = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "#Use the model with the best score from above\n",
    "#Instantiate the model\n",
    "model = XGBClassifier()\n",
    "\n",
    "#Parameter Tuning\n",
    "learning_rate = [0.0001, 0.001, 0.0015, 0.01, 0.015, 0.1]\n",
    "n_estimators = [100, 200, 300, 400, 500, 600, 700]\n",
    "subsample = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 1.0]\n",
    "param_grid = dict(learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample)\n",
    "kfold = StratifiedKFold(y, n_folds=10, shuffle=True, random_state=7)\n",
    "rand_search = RandomizedSearchCV(model, param_grid, scoring=\"roc_auc\", n_jobs=-1, cv=kfold)\n",
    "result = rand_search.fit(X, y)\n",
    "\n",
    "print(\"Model Report\")\n",
    "print(\"Best Score: %f based on %s\" % (result.best_score_, result.best_params_))\n",
    "\n",
    "param_grid = [\n",
    " {'C': [0, 0.1, 1, 10, 100], 'gamma': [0.01, 0.001, 0.0001], 'kernel': ['rbf', 'linear']},\n",
    " {'C': [0, 0.1, 1, 10, 100], 'gamma': [0.01, 0.001, 0.0001], 'kernel': ['poly'], 'degree': [1, 2, 3, 4, 5]}\n",
    "]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import cross_validation, metrics   \n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "#Standardize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit(X_train).transform(X_train)\n",
    "X_test = scaler.fit(X_test).transform(X_test)\n",
    "\n",
    "#Use the model with the best score from above\n",
    "#Instantiate the model\n",
    "estimator = SVC()\n",
    "\n",
    "#Parameter Tuning\n",
    "\n",
    "#param_grid = [{'c': [0, 0.1, 1, 10, 100], 'gamma': [0.01, 0.001, 0.0001], 'kernel': ['rbf', 'linear']}]\n",
    "param_grid = [\n",
    " {'C': [0.1, 1, 10, 100], 'gamma': [0.01, 0.001, 0.0001], 'kernel': ['rbf', 'linear']},\n",
    " {'C': [0.1, 1, 10, 100], 'gamma': [0.01, 0.001, 0.0001], 'kernel': ['poly'], 'degree': [1, 2, 3, 4, 5]}\n",
    "]\n",
    "\n",
    "kfold = StratifiedKFold(y_train, n_folds=10, shuffle=True, random_state=7)\n",
    "grid_search = GridSearchCV(estimator, param_grid, scoring=\"accuracy\", cv=kfold, n_jobs=-1)\n",
    "result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model Report\")\n",
    "print(\"Best Score: %f based on %s\" % (result.best_score_, result.best_params_))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now, use test data to check the accuracy of model with the best parameters from above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
