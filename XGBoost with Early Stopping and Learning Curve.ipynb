{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data'\n",
    "features = [\"Times pregnant\", \"Plasma glucose\", \"Diastolic BP\", \"Triceps skin fold thickness\", \"2-Hour serum insulin\", \"BMI\", \"Diabetes pedigree function\", \"Age\"]\n",
    "\n",
    "# load data\n",
    "dataset = pd.read_csv(url, header = None)\n",
    "dataset.head()\n",
    "\n",
    "dataset = dataset.values\n",
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "# fit model to training data\n",
    "model = XGBClassifier(n_estimators=500, learning_rate=0.015)\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "model.fit(X_train, y_train, eval_metric=[\"error\", \"logloss\"], eval_set=eval_set, early_stopping_rounds=10, verbose=False)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "#Get the evaluation results and use for plotting the learning curve\n",
    "results = model.evals_result()\n",
    "#print(results)\n",
    "epochs = len(results['validation_0']['error'])\n",
    "x_axis = range(0, epochs)\n",
    "\n",
    "# plot log loss learning curve (You can do same for error, just as log loss)\n",
    "plt.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "plt.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "plt.legend()\n",
    "plt.ylabel('Log Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('XGBoost Log Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
